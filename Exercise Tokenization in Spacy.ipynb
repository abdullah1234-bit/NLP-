{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a3d10de1-8b4b-475e-8c79-14d49c59caa8",
   "metadata": {},
   "source": [
    "(1) Think stats is a free book to study statistics (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n",
    "\n",
    "This book has references to many websites from where you can download free datasets. You are an NLP engineer working for some company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from this book and you want to grab all urls from this paragraph using spacy\n",
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: token has an attribute that can be used to detect a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a091d11-501a-4533-8318-d95f1656f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1231dbe5-5126-4602-b03a-f89a5492c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look\n",
      "for\n",
      "data\n",
      "to\n",
      "help\n",
      "you\n",
      "address\n",
      "the\n",
      "question\n",
      ".\n",
      "Governments\n",
      "are\n",
      "good\n",
      "sources\n",
      "because\n",
      "data\n",
      "from\n",
      "public\n",
      "research\n",
      "is\n",
      "often\n",
      "freely\n",
      "available\n",
      ".\n",
      "Good\n",
      "places\n",
      "to\n",
      "start\n",
      "include\n",
      "http://www.data.gov/\n",
      ",\n",
      "and\n",
      "http://www.science\n",
      ".\n",
      "gov/\n",
      ",\n",
      "and\n",
      "in\n",
      "the\n",
      "United\n",
      "Kingdom\n",
      ",\n",
      "http://data.gov.uk/.\n",
      "Two\n",
      "of\n",
      "my\n",
      "favorite\n",
      "data\n",
      "sets\n",
      "are\n",
      "the\n",
      "General\n",
      "Social\n",
      "Survey\n",
      "at\n",
      "http://www3.norc.org/gss+website/\n",
      ",\n",
      "and\n",
      "the\n",
      "European\n",
      "Social\n",
      "Survey\n",
      "at\n",
      "http://www.europeansocialsurvey.org/.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp (\"Look for data to help you address the question. Governments are good sources because data from public research is often freely available. Good places to start include http://www.data.gov/, and http://www.science. gov/, and in the United Kingdom, http://data.gov.uk/. Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, and the European Social Survey at http://www.europeansocialsurvey.org/.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae984de-ea57-4447-906b-50e1a35cd5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.data.gov/\n",
      "http://www.science\n",
      "http://data.gov.uk/.\n",
      "http://www3.norc.org/gss+website/\n",
      "http://www.europeansocialsurvey.org/.\n"
     ]
    }
   ],
   "source": [
    "# Extract tokens that are URLs\n",
    "links = [token.text for token in doc if token.text.startswith(\"http\")]\n",
    "\n",
    "# Print the extracted links\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec6e756b-28a5-410e-8430-693eb168c47f",
   "metadata": {},
   "source": [
    "(2) Extract all money transaction from below sentence along with currency. Output should be,\n",
    "\n",
    "two $\n",
    "\n",
    "500 €\n",
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13b5fdb-7d3f-4dc7-8702-e12e825c0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf43a8bb-ea89-4ee4-9f06-bd6818a47363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "o\n",
      "n\n",
      "y\n",
      " \n",
      "g\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "$\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "P\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "B\n",
      "r\n",
      "u\n",
      "c\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "5\n",
      "0\n",
      "0\n",
      " \n",
      "€\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "S\n",
      "t\n",
      "e\n",
      "v\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for token in transactions:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12aafc99-900a-45cd-9b78-e4999af85126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(transactions)\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "money_transactions = []\n",
    "\n",
    "# Iterate through tokens\n",
    "for token in doc:\n",
    "    if token.is_currency:  # Check if the token is a currency symbol\n",
    "        # Get the token before the currency symbol (the amount)\n",
    "        amount_token = doc[token.i - 1]  # `token.i` is the index of the token\n",
    "        money_transactions.append(f\"{amount_token.text} {token.text}\")\n",
    "\n",
    "# Print the results\n",
    "for transaction in money_transactions:\n",
    "    print(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39040337-386c-4744-8ec6-b8f759a625e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
