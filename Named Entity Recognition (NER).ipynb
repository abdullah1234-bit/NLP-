{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb1cc98-3719-4cd5-9335-f8e55db4585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdba956-c6f5-489a-89dc-fc4349ec8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG  |  Companies, agencies, institutions, etc.\n",
      "MONEY  |  Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93fcee90-a88c-4c85-b3fe-5915ebf98395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d13ea99-cf14-4c9a-b368-0c68f802841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Bloomberg | PERSON | People, including fictional\n",
      "Bloomberg | GPE | Countries, cities, states\n",
      "1982 | DATE | Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Michael Bloomberg founded Bloomberg in 1982\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcff040-7ac8-49ad-acc4-f57ce1fd658c",
   "metadata": {},
   "source": [
    "# Setting custom entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addd7f9b-69e1-4607-9ba6-a4e39c8a0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  ORG | Companies, agencies, institutions, etc.\n",
      "Twitter  |  PERSON | People, including fictional\n",
      "$45 billion  |  MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla is going to acquire Twitter for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_,\"|\" , spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6612de-6e2e-4a6f-976c-101669518f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create our own NER system in which we declare twitter as a company which our pre trained NER system not identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd6c72c-17db-4cb3-ac18-c5889cabddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  ORG\n",
      "Twitter  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "s1 = Span(doc, 0, 1, label=\"ORG\")\n",
    "s2 = Span(doc, 5, 6, label=\"ORG\")\n",
    "\n",
    "doc.set_ents([s1, s2], default=\"unmodified\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92bf5704-5e19-4b96-8ba8-69bcf503825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next part related to NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac36561b-5e25-42bc-9e6c-21b8a6d20af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the Geographical (cities, Countries, states) names from a given text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2748f33f-e5a5-449e-b115-6031d1419a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\n",
    "in Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\n",
    "in Bihar it is Litti Chowkha and so on for all other states\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba3b8f3f-a1de-410b-8e01-15948f0d23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b8907df-8da8-477c-b484-0167cbb26a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiran  |  GPE  |  Countries, cities, states\n",
      "India  |  GPE  |  Countries, cities, states\n",
      "Google  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Google  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Delhi  |  GPE  |  Countries, cities, states\n",
      "Chaat  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Gujarat  |  GPE  |  Countries, cities, states\n",
      "Dal Dhokli  |  PERSON  |  People, including fictional\n",
      "Tamilnadu  |  GPE  |  Countries, cities, states\n",
      "Pongal  |  PERSON  |  People, including fictional\n",
      "Andhrapradesh  |  GPE  |  Countries, cities, states\n",
      "Biryani  |  PERSON  |  People, including fictional\n",
      "Assam  |  GPE  |  Countries, cities, states\n",
      "Papaya Khar  |  PERSON  |  People, including fictional\n",
      "Bihar  |  GPE  |  Countries, cities, states\n",
      "Litti Chowkha  |  ORG  |  Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b54259-d1db-45cb-acdb-73703557ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiran  |  GPE  |  Countries, cities, states\n",
      "India  |  GPE  |  Countries, cities, states\n",
      "Delhi  |  GPE  |  Countries, cities, states\n",
      "Gujarat  |  GPE  |  Countries, cities, states\n",
      "Tamilnadu  |  GPE  |  Countries, cities, states\n",
      "Andhrapradesh  |  GPE  |  Countries, cities, states\n",
      "Assam  |  GPE  |  Countries, cities, states\n",
      "Bihar  |  GPE  |  Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"GPE\":  # Check if the entity is a Geopolitical Entity\n",
    "        print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e80e6198-dd33-4549-94c2-ca061fb1431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the birth dates of cricketers in the given Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccfa3467-8803-46ab-a278-699fa1d4a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Sachin Tendulkar was born on 24 April 1973, Virat Kholi was born on 5 November 1988, Dhoni was born on 7 July 1981\n",
    "and finally Ricky ponting was born on 19 December 1974.\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ae7cefa-942b-40dc-845d-97d706f9b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth Dates of Cricketers:\n",
      "24 April 1973\n",
      "5 November 1988\n",
      "7 July 1981\n",
      "19 December 1974\n"
     ]
    }
   ],
   "source": [
    "# Extract and print birth dates\n",
    "print(\"Birth Dates of Cricketers:\")\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"DATE\":\n",
    "        print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e6729-f02f-416a-97e7-d5d1910b733a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
