{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullah1234-bit/NLP-/blob/main/tf_idf_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrcHNZpQLUz"
      },
      "source": [
        "### **TF-IDF:\n",
        "\n",
        "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
        "\n",
        "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
        "\n",
        "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
        "\n",
        "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5KDovsV9ez"
      },
      "source": [
        "### **About Data: Emotion Detection**\n",
        "\n",
        "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
        "\n",
        "\n",
        "- This data consists of two columns.\n",
        "        - Comment\n",
        "        - Emotion\n",
        "- Comment are the statements or messages regarding to a particular event/situation.\n",
        "\n",
        "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
        "\n",
        "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ML2s0KWVXmv",
        "outputId": "f0726e03-2b14-4b75-cf1e-937b083b1b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataframe: (15999, 1)\n",
            "Top 5 rows of the dataframe:\n",
            "                     i didnt feel humiliated;sadness\n",
            "0  i can go from feeling so hopeless to so damned...\n",
            "1  im grabbing a minute to post i feel greedy wro...\n",
            "2  i am ever feeling nostalgic about the fireplac...\n",
            "3                         i am feeling grouchy;anger\n",
            "4  ive been feeling a little burdened lately wasn...\n"
          ]
        }
      ],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Read the dataset with the name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
        "df = pd.read_csv(\"/content/train.txt\")\n",
        "\n",
        "# Print the shape of the dataframe\n",
        "print(\"Shape of the dataframe:\", df.shape)\n",
        "\n",
        "# Print the top 5 rows of the dataframe\n",
        "print(\"Top 5 rows of the dataframe:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ94CSUdRSsQ",
        "outputId": "8d220152-dc3a-4328-9c77-8f6bc61aa13e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['i didnt feel humiliated;sadness'], dtype='object')\n",
            "                     i didnt feel humiliated;sadness\n",
            "0  i can go from feeling so hopeless to so damned...\n",
            "1  im grabbing a minute to post i feel greedy wro...\n",
            "2  i am ever feeling nostalgic about the fireplac...\n",
            "3                         i am feeling grouchy;anger\n",
            "4  ive been feeling a little burdened lately wasn...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train.txt', sep=';', header=None, names=['Text', 'Emotion'])\n",
        "\n",
        "# Check the shape\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "\n",
        "# Display the top 5 rows\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBk9EpSvRfou",
        "outputId": "b59fbc79-776a-4f54-90ae-86057dba2dce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: (16000, 2)\n",
            "                                                Text  Emotion\n",
            "0                            i didnt feel humiliated  sadness\n",
            "1  i can go from feeling so hopeless to so damned...  sadness\n",
            "2   im grabbing a minute to post i feel greedy wrong    anger\n",
            "3  i am ever feeling nostalgic about the fireplac...     love\n",
            "4                               i am feeling grouchy    anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joLuZmFpT-fY",
        "outputId": "32ab5802-16fb-4d2d-c685-056f54683666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of Emotion:\n",
            "Emotion\n",
            "joy         5362\n",
            "sadness     4666\n",
            "anger       2159\n",
            "fear        1937\n",
            "love        1304\n",
            "surprise     572\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the distribution of emotions\n",
        "print(\"Distribution of Emotion:\")\n",
        "print(df['Emotion'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Define oversampling strategy\n",
        "oversample = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = oversample.fit_resample(df[['Text']], df['Emotion'])\n",
        "\n",
        "# Combine back into a DataFrame\n",
        "resampled_df = pd.DataFrame({'Text': X_resampled['Text'], 'Emotion': y_resampled})\n",
        "print(resampled_df['Emotion'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGunzi8BSdIh",
        "outputId": "497efc86-5652-4d1a-ee2d-d90691e4eceb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion\n",
            "sadness     5362\n",
            "anger       5362\n",
            "love        5362\n",
            "surprise    5362\n",
            "fear        5362\n",
            "joy         5362\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPxiqT_TT-hx",
        "outputId": "cfa00e8a-72f0-446e-8810-855cdcf33ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  Emotion  Emotion_num\n",
            "0                            i didnt feel humiliated  sadness            3\n",
            "1  i can go from feeling so hopeless to so damned...  sadness            3\n",
            "2   im grabbing a minute to post i feel greedy wrong    anger            2\n",
            "3  i am ever feeling nostalgic about the fireplac...     love            4\n",
            "4                               i am feeling grouchy    anger            2\n"
          ]
        }
      ],
      "source": [
        "# Create a mapping for emotions\n",
        "emotion_mapping = {\n",
        "    'joy': 0,\n",
        "    'fear': 1,\n",
        "    'anger': 2,\n",
        "    'sadness': 3,   # Optional if sadness and others are needed\n",
        "    'love': 4,\n",
        "    'surprise': 5\n",
        "}\n",
        "\n",
        "# Add a new column based on the mapping\n",
        "df['Emotion_num'] = df['Emotion'].map(emotion_mapping)\n",
        "\n",
        "# Print the top 5 rows to verify\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ACq6pDkZ4sA"
      },
      "source": [
        "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tj_xYgthX7UF"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# load english language model and create nlp object from it\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "#use this utility function to get the preprocessed text data\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw2b69sDUP6Z",
        "outputId": "b9338a8a-b010-42a4-da07-e08ec707859e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Text', 'Emotion', 'Emotion_num'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xqW1i19wX7Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfe9f1e-ceb2-480a-c77b-a4f7581a5901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  Emotion  Emotion_num  \\\n",
            "0                            i didnt feel humiliated  sadness            3   \n",
            "1  i can go from feeling so hopeless to so damned...  sadness            3   \n",
            "2   im grabbing a minute to post i feel greedy wrong    anger            2   \n",
            "3  i am ever feeling nostalgic about the fireplac...     love            4   \n",
            "4                               i am feeling grouchy    anger            2   \n",
            "\n",
            "                      preprocessed_comment  \n",
            "0                       not feel humiliate  \n",
            "1  feel hopeless damned hopeful care awake  \n",
            "2     m grab minute post feel greedy wrong  \n",
            "3   feel nostalgic fireplace know property  \n",
            "4                             feel grouchy  \n"
          ]
        }
      ],
      "source": [
        "# Apply the preprocessing function to the 'Text' column\n",
        "df['preprocessed_comment'] = df['Text'].apply(preprocess)\n",
        "\n",
        "# Check the updated DataFrame\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q24oRlMcai9l"
      },
      "source": [
        "**Build a model with pre processed text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ahdd2mgxX7dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c5c395-32f1-41b1-97fc-dfde5c0388ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (12800,)\n",
            "Shape of X_test: (3200,)\n",
            "Shape of y_train: (12800,)\n",
            "Shape of y_test: (3200,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data using preprocessed_comment and Emotion_num for stratified sampling\n",
        "X = df['preprocessed_comment']\n",
        "y = df['Emotion_num']\n",
        "\n",
        "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022, stratify=y)\n",
        "\n",
        "# Print the shapes of the train and test sets to confirm the split\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqonfpeYasOE"
      },
      "source": [
        "**Let's check the scores with our best model till now**\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wYgFs3auLQ"
      },
      "source": [
        "**Attempt1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigrams and bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khtu32z1XmmE",
        "outputId": "d330c034-6e9b-46d7-8fe5-6d7a58c3ec1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88      1072\n",
            "           1       0.84      0.83      0.84       387\n",
            "           2       0.87      0.83      0.85       432\n",
            "           3       0.87      0.90      0.88       933\n",
            "           4       0.77      0.69      0.73       261\n",
            "           5       0.86      0.64      0.74       115\n",
            "\n",
            "    accuracy                           0.85      3200\n",
            "   macro avg       0.84      0.80      0.82      3200\n",
            "weighted avg       0.85      0.85      0.85      3200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create the classification pipeline\n",
        "model_rf_ngram = make_pipeline(\n",
        "    CountVectorizer(ngram_range=(1, 2)),  # Use both unigrams and bigrams\n",
        "    RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=2022)  # Random Forest Classifier\n",
        ")\n",
        "\n",
        "# Train-test split (use the preprocessed comments as input features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_comment'], df['Emotion_num'], test_size=0.2, random_state=2022, stratify=df['Emotion_num'])\n",
        "\n",
        "# Train the model\n",
        "model_rf_ngram.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_rf_ngram.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9GZPaQbbJbx"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2y1Cy4Bauxu",
        "outputId": "1fb5f94e-113f-4bc0-a6c4-d2fcd308c7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84      1072\n",
            "           1       0.79      0.82      0.80       387\n",
            "           2       0.84      0.83      0.83       432\n",
            "           3       0.89      0.81      0.85       933\n",
            "           4       0.76      0.64      0.69       261\n",
            "           5       0.81      0.57      0.67       115\n",
            "\n",
            "    accuracy                           0.82      3200\n",
            "   macro avg       0.81      0.76      0.78      3200\n",
            "weighted avg       0.82      0.82      0.82      3200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create the classification pipeline with TF-IDF and Random Forest\n",
        "model_rf_tfidf = make_pipeline(\n",
        "    TfidfVectorizer(),  # Use TF-IDF vectorizer for text data preprocessing\n",
        "    RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=2022)  # RandomForest as classifier\n",
        ")\n",
        "\n",
        "# Train-test split (use the preprocessed comments as input features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_comment'], df['Emotion_num'], test_size=0.2, random_state=2022, stratify=df['Emotion_num'])\n",
        "\n",
        "# Train the model\n",
        "model_rf_tfidf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model_rf_tfidf.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}